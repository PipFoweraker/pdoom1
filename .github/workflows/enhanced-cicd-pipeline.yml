name: Enhanced CI/CD Pipeline

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main, develop ]
  schedule:
    # Run daily maintenance at 2 AM UTC
    - cron: '0 2 * * *'
  workflow_dispatch:
    inputs:
      pipeline_stage:
        description: 'Pipeline stage to run'
        required: true
        default: 'full'
        type: choice
        options:
          - 'full'
          - 'quality-only'
          - 'sync-only'
          - 'cleanup-only'
          - 'nuke-develop'
      dry_run:
        description: 'Run in dry-run mode'
        required: true
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'

env:
  PYTHON_VERSION: '3.11'

jobs:
  # Stage 1: Basic Validation (< 30 seconds)
  basic-validation:
    name: "Stage 1: Basic Validation"
    runs-on: ubuntu-latest
    if: github.event_name != 'schedule' || github.event.inputs.pipeline_stage == 'full' || github.event.inputs.pipeline_stage == 'quality-only'
    
    outputs:
      validation-passed: ${{ steps.validation.outputs.passed }}
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Cache dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: ASCII Compliance Check
        id: ascii-check
        run: |
          echo "🔤 Checking ASCII compliance..."
          python scripts/intelligent_ascii_converter.py --dry-run
          if [ $? -eq 0 ]; then
            echo "SUCCESS ASCII compliance: PASSED"
          else
            echo "ERROR ASCII compliance: FAILED"
            exit 1
          fi
          
      - name: Import Structure Validation
        id: import-check
        run: |
          echo "📦 Validating import structure..."
          python -c "
          try:
              from src.core.game_state import GameState
              from src.services.version import get_display_version
              print('SUCCESS Core imports: PASSED')
          except ImportError as e:
              print(f'ERROR Core imports: FAILED - {e}')
              exit(1)
          "
          
      - name: Version Consistency Check
        id: version-check
        run: |
          echo "🏷 Checking version consistency..."
          python -c "
          from src.services.version import get_display_version
          version = get_display_version()
          print(f'Current version: {version}')
          
          if 'dev' in version.lower() or 'placeholder' in version.lower():
              print('ERROR Development placeholder version detected')
              exit(1)
          
          print('SUCCESS Version consistency: PASSED')
          "
          
      - name: File Structure Validation
        id: structure-check
        run: |
          echo "FOLDER Validating file structure..."
          required_files=(
            "main.py"
            "src/core/game_state.py" 
            "src/services/version.py"
            "requirements.txt"
            "README.md"
          )
          
          for file in "${required_files[@]}"; do
            if [ ! -f "$file" ]; then
              echo "ERROR Missing required file: $file"
              exit 1
            fi
          done
          
          echo "SUCCESS File structure: PASSED"
          
      - name: Set validation status
        id: validation
        run: |
          echo "passed=true" >> $GITHUB_OUTPUT
          echo "SUCCESS Stage 1 Complete: Basic validation passed"

  # Stage 2: Code Quality (< 2 minutes)
  code-quality:
    name: "Stage 2: Code Quality"
    runs-on: ubuntu-latest
    needs: basic-validation
    if: needs.basic-validation.outputs.validation-passed == 'true'
    
    outputs:
      quality-score: ${{ steps.quality-metrics.outputs.score }}
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Restore dependencies cache
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          
      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
          
      - name: Development Standards Check
        run: |
          echo "CLIPBOARD Running comprehensive standards enforcement..."
          python scripts/enforce_standards.py --check-all
          
      - name: Import Cleanup Check
        run: |
          echo "🧹 Checking for unused imports..."
          python -m autoflake --remove-all-unused-imports --remove-unused-variables --check --recursive src/
          
      - name: Type Annotation Coverage
        id: type-coverage
        run: |
          echo "🏷 Checking type annotation coverage..."
          # TODO: Implement type annotation coverage checker
          echo "type_coverage=85" >> $GITHUB_OUTPUT
          
      - name: Code Quality Metrics
        id: quality-metrics
        run: |
          echo "METRICS Collecting quality metrics..."
          
          # Calculate overall quality score
          type_coverage=${{ steps.type-coverage.outputs.type_coverage }}
          
          if [ "$type_coverage" -ge 80 ]; then
            quality_score="HIGH"
          elif [ "$type_coverage" -ge 60 ]; then
            quality_score="MEDIUM"
          else
            quality_score="LOW"
          fi
          
          echo "score=$quality_score" >> $GITHUB_OUTPUT
          echo "SUCCESS Quality score: $quality_score (Type coverage: $type_coverage%)"

      - name: Project Health Assessment
        id: health-check
        run: |
          echo "HEALTH Running comprehensive project health assessment..."
          
          # Run health check and capture output
          python scripts/project_health.py --ci-mode --output health_report.json
          
          # Get machine-readable CI/CD metrics
          health_output=$(python scripts/health_tracker.py --show-trends --format ci)
          
          # Extract key metrics for GitHub Actions
          health_score=$(echo "$health_output" | grep "CICD_HEALTH_SCORE=" | cut -d= -f2)
          health_status=$(echo "$health_output" | grep "CICD_HEALTH_STATUS=" | cut -d= -f2)
          health_trend=$(echo "$health_output" | grep "CICD_HEALTH_TREND_PERCENTAGE=" | cut -d= -f2)
          
          # Set GitHub Actions environment variables
          echo "HEALTH_SCORE=$health_score" >> $GITHUB_ENV
          echo "HEALTH_STATUS=$health_status" >> $GITHUB_ENV
          echo "HEALTH_TREND=$health_trend" >> $GITHUB_ENV
          
          # Set outputs for dependent jobs
          echo "health-score=$health_score" >> $GITHUB_OUTPUT
          echo "health-status=$health_status" >> $GITHUB_OUTPUT
          echo "health-trend=$health_trend" >> $GITHUB_OUTPUT
          
          # Display health summary
          echo "SUMMARY Project Health: $health_score/100 ($health_status, trend: $health_trend%)"
          
      - name: Health Gate Check
        run: |
          echo "GATE Running automated health gate check..."
          
          # Run health gate check (returns exit code 0/1)
          python scripts/ci_health_integration.py --gate-check
          gate_result=$?
          
          if [ $gate_result -eq 0 ]; then
            echo "SUCCESS Health gate: PASSED (Score: ${{ env.HEALTH_SCORE }}/100)"
          else
            echo "ERROR Health gate: FAILED (Score: ${{ env.HEALTH_SCORE }}/100)"
            echo "HELP Run 'python scripts/health_automation.py --mode improvement' to fix issues"
            exit 1
          fi
          
      - name: Upload Health Report
        uses: actions/upload-artifact@v3
        with:
          name: health-report-${{ github.sha }}
          path: health_report.json
          retention-days: 30

  # Stage 3: Integration Testing (< 5 minutes)
  integration-testing:
    name: "Stage 3: Integration Testing"
    runs-on: ubuntu-latest
    needs: code-quality
    if: needs.code-quality.outputs.quality-score != 'LOW' && needs.code-quality.outputs.health-score >= 70
    
    strategy:
      matrix:
        python-version: ['3.9', '3.11', '3.12']
        
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Setup Python ${{ matrix.python-version }}
        uses: actions/setup-python@v4
        with:
          python-version: ${{ matrix.python-version }}
          
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
      - name: Run Test Suite
        id: test-suite
        run: |
          echo "🧪 Running comprehensive test suite..."
          timeout 120 python -m unittest discover tests -v
          
      - name: Performance Benchmark
        id: performance
        run: |
          echo "⚡ Running performance benchmarks..."
          start_time=$(date +%s%N)
          python -c "
          from src.core.game_state import GameState
          import time
          
          start = time.time()
          gs = GameState('benchmark-test')
          end = time.time()
          
          startup_time = end - start
          print(f'Startup time: {startup_time:.3f}s')
          
          if startup_time > 2.0:
              print('ERROR Performance: Startup time too slow')
              exit(1)
          else:
              print('SUCCESS Performance: Startup time acceptable')
          "
          
      - name: Memory Usage Check
        run: |
          echo "SAVE Checking memory usage..."
          python -c "
          import psutil
          import os
          from src.core.game_state import GameState
          
          process = psutil.Process(os.getpid())
          initial_memory = process.memory_info().rss / 1024 / 1024  # MB
          
          gs = GameState('memory-test')
          
          final_memory = process.memory_info().rss / 1024 / 1024  # MB
          memory_increase = final_memory - initial_memory
          
          print(f'Memory usage: {final_memory:.1f}MB (increase: {memory_increase:.1f}MB)')
          
          if final_memory > 200:
              print('ERROR Memory: Usage too high')
              exit(1)
          else:
              print('SUCCESS Memory: Usage acceptable')
          "

  # Stage 4: Automated Synchronization
  automated-sync:
    name: "Stage 4: Automated Sync"
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.pipeline_stage == 'full' || github.event.inputs.pipeline_stage == 'sync-only'
    
    permissions:
      issues: write
      contents: write
      pull-requests: write
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install GitHub CLI
        run: |
          sudo apt-get update
          sudo apt-get install gh
          
      - name: Authenticate GitHub CLI
        run: |
          echo "${{ secrets.GITHUB_TOKEN }}" | gh auth login --with-token
          
      - name: Bidirectional Issue Sync
        run: |
          echo "REFRESH Running bidirectional issue sync..."
          dry_run_flag=""
          if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
            dry_run_flag="--dry-run"
          else
            dry_run_flag="--live"
          fi
          
          python scripts/issue_sync_bidirectional.py $dry_run_flag --sync-all
          
      - name: Branch Status Report
        run: |
          echo "METRICS Generating branch status report..."
          python scripts/branch_manager.py --report
          
      - name: Auto-merge Ready PRs
        if: github.event.inputs.dry_run != 'true'
        run: |
          echo "LAUNCH Auto-merging ready PRs..."
          python scripts/branch_manager.py --live --auto-merge-ready

  # Stage 5: Automated Cleanup
  automated-cleanup:
    name: "Stage 5: Automated Cleanup"
    runs-on: ubuntu-latest
    if: github.event_name == 'schedule' || github.event.inputs.pipeline_stage == 'cleanup-only'
    
    permissions:
      contents: write
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Install GitHub CLI
        run: |
          sudo apt-get update
          sudo apt-get install gh
          
      - name: Authenticate GitHub CLI
        run: |
          echo "${{ secrets.GITHUB_TOKEN }}" | gh auth login --with-token
          
      - name: Clean up stale branches
        run: |
          echo "🧹 Cleaning up stale branches..."
          dry_run_flag=""
          if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
            dry_run_flag="--dry-run"
          else
            dry_run_flag="--live"
          fi
          
          python scripts/branch_manager.py $dry_run_flag --cleanup-all --stale-days 30

  # Special: Nuclear Option for Develop Branch
  nuke-develop:
    name: "Nuclear: Reset Develop Branch"
    runs-on: ubuntu-latest
    if: github.event.inputs.pipeline_stage == 'nuke-develop'
    
    permissions:
      contents: write
      
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          fetch-depth: 0  # Need full history for branch operations
          
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          
      - name: Configure Git
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "actions@github.com"
          
      - name: Nuclear Reset of Develop Branch
        run: |
          echo "💥 NUCLEAR OPTION: Resetting develop branch..."
          dry_run_flag=""
          confirm_flag=""
          
          if [ "${{ github.event.inputs.dry_run }}" = "true" ]; then
            dry_run_flag="--dry-run"
          else
            dry_run_flag="--live"
            confirm_flag="--confirm"
          fi
          
          python scripts/branch_manager.py $dry_run_flag --nuke-develop $confirm_flag

  # Quality Dashboard Update
  quality-dashboard:
    name: "Quality Dashboard Update"
    runs-on: ubuntu-latest
    needs: [basic-validation, code-quality, integration-testing]
    if: always() && (github.event_name == 'push' && github.ref == 'refs/heads/main')
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Update Quality Metrics
        run: |
          echo "METRICS Updating quality dashboard..."
          
          # Create quality metrics file
          cat > quality_metrics.json << EOF
          {
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "validation_passed": "${{ needs.basic-validation.outputs.validation-passed }}",
            "quality_score": "${{ needs.code-quality.outputs.quality-score }}",
            "tests_passed": "${{ needs.integration-testing.result == 'success' }}",
            "commit_sha": "${{ github.sha }}",
            "branch": "${{ github.ref_name }}"
          }
          EOF
          
          echo "Quality metrics updated"

  # Notification Summary
  pipeline-summary:
    name: "Pipeline Summary"
    runs-on: ubuntu-latest
    needs: [basic-validation, code-quality, integration-testing, automated-sync, automated-cleanup]
    if: always()
    
    steps:
      - name: Generate Pipeline Summary
        run: |
          echo "🏁 CI/CD Pipeline Summary"
          echo "========================="
          echo ""
          echo "CLIPBOARD Stage Results:"
          echo "  - Basic Validation: ${{ needs.basic-validation.result }}"
          echo "  - Code Quality: ${{ needs.code-quality.result }}"
          echo "  - Integration Testing: ${{ needs.integration-testing.result }}"
          echo "  - Automated Sync: ${{ needs.automated-sync.result }}"
          echo "  - Automated Cleanup: ${{ needs.automated-cleanup.result }}"
          echo ""
          
          if [ "${{ needs.basic-validation.result }}" = "success" ] && 
             [ "${{ needs.code-quality.result }}" = "success" ] && 
             [ "${{ needs.integration-testing.result }}" = "success" ]; then
            echo "SUCCESS PIPELINE SUCCESS: All quality gates passed"
            echo "LAUNCH Ready for deployment"
          else
            echo "ERROR PIPELINE FAILURE: Quality gates failed"
            echo "TOOLS Manual intervention required"
          fi
          
          echo ""
          echo "METRICS Quality Metrics:"
          echo "  - Quality Score: ${{ needs.code-quality.outputs.quality-score }}"
          echo "  - Pipeline Run: ${{ github.run_number }}"
          echo "  - Commit: ${{ github.sha }}"